{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4138b826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "693a9717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie about a distressed, drifting young man.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characters or the audience, nearly half of whom walked out.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and clever camera angles, the movie disappointed - became even more ridiculous - as the acting was poor and the plot and lines almost non-existent.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo is trying to find a song that keeps running through his head.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>I just got bored watching Jessice Lange take her clothes off!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>Unfortunately, any virtue in this film's production work was lost on a regrettable script.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>In a word, it is embarrassing.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>Exceptionally bad!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>All in all its an insult to one's intelligence and a huge waste of money.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>748 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                             text  \\\n",
       "0                                                                                                         A very, very, very slow-moving, aimless movie about a distressed, drifting young man.     \n",
       "1                                                                                             Not sure who was more lost - the flat characters or the audience, nearly half of whom walked out.     \n",
       "2    Attempting artiness with black & white and clever camera angles, the movie disappointed - became even more ridiculous - as the acting was poor and the plot and lines almost non-existent.     \n",
       "3                                                                                                                                                    Very little music or anything to speak of.     \n",
       "4                                                                                    The best scene in the movie was when Gerardo is trying to find a song that keeps running through his head.     \n",
       "..                                                                                                                                                                                            ...   \n",
       "743                                                                                                                               I just got bored watching Jessice Lange take her clothes off!     \n",
       "744                                                                                                  Unfortunately, any virtue in this film's production work was lost on a regrettable script.     \n",
       "745                                                                                                                                                              In a word, it is embarrassing.     \n",
       "746                                                                                                                                                                          Exceptionally bad!     \n",
       "747                                                                                                                   All in all its an insult to one's intelligence and a huge waste of money.     \n",
       "\n",
       "     label  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        1  \n",
       "..     ...  \n",
       "743      0  \n",
       "744      0  \n",
       "745      0  \n",
       "746      0  \n",
       "747      0  \n",
       "\n",
       "[748 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "df = pd.read_csv('https://gist.githubusercontent.com/fmnobar/88703ec6a1f37b3eabf126ad38c392b8/raw/76b84540ccd4b0b207a6978eb7e9d938275886ff/imdb_labelled.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfb34e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    386\n",
       "0    362\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a60e6fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a2fbf91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A very, very, very slow-moving, aimless movie about a distressed, drifting young man.  '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = df.text[0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbb2333",
   "metadata": {},
   "source": [
    "### Tokenize the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0229a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/karen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['A', 'very', ',', 'very', ',', 'very', 'slow-moving', ',', 'aimless', 'movie']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "sample_tokens = word_tokenize(sample)\n",
    "sample_tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb4d62d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'very'),\n",
       " ('very', ','),\n",
       " (',', 'very'),\n",
       " ('very', ','),\n",
       " (',', 'very'),\n",
       " ('very', 'slow-moving'),\n",
       " ('slow-moving', ','),\n",
       " (',', 'aimless'),\n",
       " ('aimless', 'movie'),\n",
       " ('movie', 'about'),\n",
       " ('about', 'a'),\n",
       " ('a', 'distressed'),\n",
       " ('distressed', ','),\n",
       " (',', 'drifting'),\n",
       " ('drifting', 'young'),\n",
       " ('young', 'man'),\n",
       " ('man', '.')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import bigrams\n",
    "\n",
    "sample_bitokens = list(bigrams(sample_tokens))\n",
    "sample_bitokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5198e983",
   "metadata": {},
   "source": [
    "#### Check Frequency of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0b939f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 4),\n",
       " ('very', 3),\n",
       " ('A', 1),\n",
       " ('slow-moving', 1),\n",
       " ('aimless', 1),\n",
       " ('movie', 1),\n",
       " ('about', 1),\n",
       " ('a', 1),\n",
       " ('distressed', 1),\n",
       " ('drifting', 1)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "sample_freqdist = FreqDist(sample_tokens)\n",
    "sample_freqdist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "308bffbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 2),\n",
       " ('Not', 1),\n",
       " ('sure', 1),\n",
       " ('who', 1),\n",
       " ('was', 1),\n",
       " ('more', 1),\n",
       " ('lost', 1),\n",
       " ('-', 1),\n",
       " ('flat', 1),\n",
       " ('characters', 1)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a function to accept a text and n and returns top n most common tokens\n",
    "def top_n(text, n):\n",
    "    # Create tokens\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Create the frequency distribution\n",
    "    freqdist = FreqDist(tokens)\n",
    "    \n",
    "    # Return the top n most common ones\n",
    "    return freqdist.most_common(n)\n",
    "\n",
    "# Try it on the sample\n",
    "top_n(df.text[1], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bace608",
   "metadata": {},
   "source": [
    "#### Data Transformation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6b447e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>about</th>\n",
       "      <th>acting</th>\n",
       "      <th>aimless</th>\n",
       "      <th>almost</th>\n",
       "      <th>and</th>\n",
       "      <th>angles</th>\n",
       "      <th>anything</th>\n",
       "      <th>artiness</th>\n",
       "      <th>as</th>\n",
       "      <th>attempting</th>\n",
       "      <th>...</th>\n",
       "      <th>trying</th>\n",
       "      <th>very</th>\n",
       "      <th>walked</th>\n",
       "      <th>was</th>\n",
       "      <th>when</th>\n",
       "      <th>white</th>\n",
       "      <th>who</th>\n",
       "      <th>whom</th>\n",
       "      <th>with</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   about  acting  aimless  almost  and  angles  anything  artiness  as  \\\n",
       "0      1       0        1       0    0       0         0         0   0   \n",
       "1      0       0        0       0    0       0         0         0   0   \n",
       "2      0       1        0       1    3       1         0         1   1   \n",
       "3      0       0        0       0    0       0         1         0   0   \n",
       "4      0       0        0       0    0       0         0         0   0   \n",
       "\n",
       "   attempting  ...  trying  very  walked  was  when  white  who  whom  with  \\\n",
       "0           0  ...       0     3       0    0     0      0    0     0     0   \n",
       "1           0  ...       0     0       1    1     0      0    1     1     0   \n",
       "2           1  ...       0     0       0    1     0      1    0     0     1   \n",
       "3           0  ...       0     1       0    0     0      0    0     0     0   \n",
       "4           0  ...       1     0       0    1     1      0    0     0     0   \n",
       "\n",
       "   young  \n",
       "0      1  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the package\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def create_dtm(series):\n",
    "    # Create an instance of the class\n",
    "    cv = CountVectorizer()\n",
    "    \n",
    "    # Create a document term matrix from the provided series\n",
    "    dtm = cv.fit_transform(series)\n",
    "    \n",
    "    # Convert the sparse array to a dense array\n",
    "    dtm = dtm.todense()\n",
    "    \n",
    "    # Get column names\n",
    "    features = cv.get_feature_names()\n",
    "    \n",
    "    # Create a dataframe\n",
    "    dtm_df = pd.DataFrame(dtm, columns = features)\n",
    "    \n",
    "    # Return the dataframe\n",
    "    return dtm_df\n",
    "\n",
    "# Try the function on the top 5 rows of the df['text']\n",
    "create_dtm(df.text.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0deb1987",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbcdaafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>liked</td>\n",
       "      <td>1.286747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>wonderful</td>\n",
       "      <td>1.242158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>funny</td>\n",
       "      <td>1.112821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>great</td>\n",
       "      <td>1.068772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2949</th>\n",
       "      <td>well</td>\n",
       "      <td>1.043139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>beautiful</td>\n",
       "      <td>1.042833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1.035405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>brilliant</td>\n",
       "      <td>1.014080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>excellent</td>\n",
       "      <td>1.009914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2203</th>\n",
       "      <td>right</td>\n",
       "      <td>0.985806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tokens  Coefficients\n",
       "1567      liked      1.286747\n",
       "2997  wonderful      1.242158\n",
       "1104      funny      1.112821\n",
       "1182      great      1.068772\n",
       "2949       well      1.043139\n",
       "246   beautiful      1.042833\n",
       "0            10      1.035405\n",
       "344   brilliant      1.014080\n",
       "908   excellent      1.009914\n",
       "2203      right      0.985806"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def top_n_tokens(text, sentiment, n):\n",
    "    # Create an instance of the class\n",
    "    lgr = LogisticRegression(solver = 'lbfgs', max_iter = 2500, random_state = 1234)\n",
    "    cv = CountVectorizer()\n",
    "    \n",
    "    # create the DTM\n",
    "    dtm = cv.fit_transform(text)\n",
    "    \n",
    "    # Fit the logistic regression model\n",
    "    lgr.fit(dtm, sentiment)\n",
    "    \n",
    "    # Get the coefficients\n",
    "    coefs = lgr.coef_[0]\n",
    "    \n",
    "    # Create the features / column names\n",
    "    features = cv.get_feature_names()\n",
    "    \n",
    "    # create the dataframe\n",
    "    df = pd.DataFrame({'Tokens' : features, 'Coefficients' : coefs})\n",
    "    \n",
    "    # Return the largest n\n",
    "    return df.nlargest(n, 'Coefficients')\n",
    "\n",
    "# Test it on the df['text']\n",
    "top_n_tokens(df.text, df.label, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16dec3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>bad</td>\n",
       "      <td>-1.872751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>awful</td>\n",
       "      <td>-1.334554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2530</th>\n",
       "      <td>stupid</td>\n",
       "      <td>-1.175416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>cheap</td>\n",
       "      <td>-1.139512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>no</td>\n",
       "      <td>-1.137234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>even</td>\n",
       "      <td>-1.091436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3017</th>\n",
       "      <td>would</td>\n",
       "      <td>-1.047931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3012</th>\n",
       "      <td>worst</td>\n",
       "      <td>-1.039231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2923</th>\n",
       "      <td>waste</td>\n",
       "      <td>-1.038206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>nothing</td>\n",
       "      <td>-0.973472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tokens  Coefficients\n",
       "222       bad     -1.872751\n",
       "211     awful     -1.334554\n",
       "2530   stupid     -1.175416\n",
       "441     cheap     -1.139512\n",
       "1802       no     -1.137234\n",
       "893      even     -1.091436\n",
       "3017    would     -1.047931\n",
       "3012    worst     -1.039231\n",
       "2923    waste     -1.038206\n",
       "1819  nothing     -0.973472"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bottom_n_tokens(text, sentiment, n):\n",
    "    # Create an instance of the class\n",
    "    lgr = LogisticRegression(solver = 'lbfgs', max_iter = 2500, random_state = 1234)\n",
    "    cv = CountVectorizer()\n",
    "    \n",
    "    # create the DTM\n",
    "    dtm = cv.fit_transform(text)\n",
    "    \n",
    "    # Fit the logistic regression model\n",
    "    lgr.fit(dtm, sentiment)\n",
    "    \n",
    "    # Get the coefficients\n",
    "    coefs = lgr.coef_[0]\n",
    "    \n",
    "    # Create the features / column names\n",
    "    features = cv.get_feature_names()\n",
    "    \n",
    "    # create the dataframe\n",
    "    df = pd.DataFrame({'Tokens' : features, 'Coefficients' : coefs})\n",
    "    \n",
    "    # Return the largest n\n",
    "    return df.nsmallest(n, 'Coefficients')\n",
    "\n",
    "# Test it on the df['text']\n",
    "bottom_n_tokens(df.text, df.label, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d5e0a2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Using cached textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "Requirement already satisfied: nltk>=3.1 in /home/karen/anaconda3/lib/python3.9/site-packages (from textblob) (3.6.5)\n",
      "Requirement already satisfied: click in /home/karen/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (8.0.3)\n",
      "Requirement already satisfied: joblib in /home/karen/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/karen/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in /home/karen/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (4.62.3)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.17.1\n",
      "Polarity is 0.18 and subjectivity is 0.4.\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob \n",
    "\n",
    "import textblob\n",
    "from textblob import TextBlob\n",
    "\n",
    "def polarity_subjectivity(text = sample, print_results = False):\n",
    "    # Create an instance of TextBlob\n",
    "    tb = TextBlob(text)\n",
    "    \n",
    "    # If the condition is met, print the results, otherwise, return the tuple\n",
    "    if print_results:\n",
    "        print(f\"Polarity is {round(tb.sentiment[0], 2)} and subjectivity is {round(tb.sentiment[1], 2)}.\")\n",
    "    else:\n",
    "        return(tb.sentiment[0], tb.sentiment[1])\n",
    "    \n",
    "# Test the function on our sample\n",
    "polarity_subjectivity(sample, print_results = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5982d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    18\n",
       "1    21\n",
       "2    33\n",
       "3     9\n",
       "4    22\n",
       "5    27\n",
       "6     4\n",
       "7    17\n",
       "8     4\n",
       "9    11\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the first function that counts the number of tokens in a given string\n",
    "def token_count(string):\n",
    "    return len(word_tokenize(string))\n",
    "\n",
    "# Define the second function that applies the token_count function to a given Pandas Series\n",
    "def series_tokens(series):\n",
    "    return series.apply(token_count)\n",
    "\n",
    "# Apply the function to the top 10 rows of the dataframe\n",
    "series_tokens(df.text.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07bf2026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 (0.18, 0.395)\n",
       "1    (0.014583333333333337, 0.4201388888888889)\n",
       "2    (-0.12291666666666666, 0.5145833333333333)\n",
       "3                  (-0.24375000000000002, 0.65)\n",
       "4                                    (1.0, 0.3)\n",
       "5                                   (-0.1, 0.5)\n",
       "6                                   (-0.2, 0.0)\n",
       "7                     (0.7, 0.6000000000000001)\n",
       "8                                   (-0.2, 0.5)\n",
       "9                                    (0.7, 0.8)\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the function\n",
    "def series_polarity_subjectivity(series):\n",
    "    return series.apply(polarity_subjectivity)\n",
    "\n",
    "# Apply to the top 10 rows of the df['text']\n",
    "series_polarity_subjectivity(df['text'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70e454b",
   "metadata": {},
   "source": [
    "#### Measure of Complexity — Lexical Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1dde25b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.722222\n",
       "1    0.952381\n",
       "2    0.848485\n",
       "3    1.000000\n",
       "4    1.000000\n",
       "5    0.814815\n",
       "6    1.000000\n",
       "7    0.941176\n",
       "8    1.000000\n",
       "9    0.909091\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def complexity(string):\n",
    "    # Create a list of all tokens\n",
    "    total_tokens = word_tokenize(string)\n",
    "    \n",
    "    # Create a set of all tokens (which only keeps unique values)\n",
    "    unique_tokens = set(word_tokenize(string))\n",
    "    \n",
    "    # Return the complexity measure\n",
    "    return len(unique_tokens) / len(total_tokens)\n",
    "\n",
    "# Apply to the top 10 rows of the dataframe\n",
    "df.text.head(10).apply(complexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f80354",
   "metadata": {},
   "source": [
    "#### Text Cleanup — Stopwords and Non-Alphabeticals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c5abc48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/karen/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# Import library\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Select only English stopwords\n",
    "english_stop_words = stopwords.words('english')\n",
    "\n",
    "# Print the first 20\n",
    "print(english_stop_words[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c12b320f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                 [,, ,, slow-moving, ,, aimless, movie, distressed, ,, drifting, young, man, .]\n",
       "1                                                                                                        [sure, lost, -, flat, characters, audience, ,, nearly, half, walked, .]\n",
       "2    [Attempting, artiness, black, &, white, clever, camera, angles, ,, movie, disappointed, -, became, even, ridiculous, -, acting, poor, plot, lines, almost, non-existent, .]\n",
       "3                                                                                                                                            [little, music, anything, speak, .]\n",
       "4                                                                                                     [best, scene, movie, Gerardo, trying, find, song, keeps, running, head, .]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stopword_remover(string):\n",
    "    # Tokenize the string\n",
    "    tokens = word_tokenize(string)\n",
    "    \n",
    "    # Create a list of English stopwords\n",
    "    english_stopwords = stopwords.words('english')\n",
    "    \n",
    "    # Return non-stopwords\n",
    "    return [w for w in tokens if w.lower() not in english_stopwords]\n",
    "\n",
    "# Apply to the top 5 rows of our df['text']\n",
    "df.text.head(5).apply(stopword_remover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9757a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
